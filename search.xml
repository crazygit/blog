<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[10分钟入门Pandas]]></title>
    <url>%2F2017%2F12%2F20%2F10-minutes-to-pandas%2F</url>
    <content type="text"><![CDATA[参考: 10 Minutes to pandas 安装支持的python版本: 2.7, 3.5, 3.6 $ pip install pandas 检查本地的pandas运行环境是否完整，可以运行pandas的单元测试用例 $ pip install pytest &gt;&gt;&gt; import pandas as pd &gt;&gt;&gt; pd.test() 获取当前使用pandas的版本信息 &gt;&gt;&gt; import pandas as pd &gt;&gt;&gt; pd.__version__ &apos;0.21.1&apos; 概览pandas的基本数据结构: Series: 一维数据 DataFrame: 二维数据 Panel: 三维数据(从0.20.0版本开始，已经不再推荐使用) Panel4D, PanelND(不再推荐使用) DataFrame是由Series构成的 创建Series创建Series最简单的方法 &gt;&gt;&gt; s = pd.Series(data, index=index) data可以是不同的类型: python字典 ndarray 标量(比如: 5) 使用ndarray创建(From ndarray)如果data是ndarray,那么index的长度必须和data的长度相同，当没有明确index参数时，默认使用[0, ... len(data) - 1]作为index。 &gt;&gt;&gt; import pandas as pd &gt;&gt;&gt; import numpy as np &gt;&gt;&gt; s = pd.Series(np.random.randn(5), index=[&apos;a&apos;, &apos;b&apos;, &apos;c&apos;, &apos;d&apos;, &apos;e&apos;]) &gt;&gt;&gt; s a 0.654385 b 0.055691 c 0.856054 d 0.621810 e 1.802872 dtype: float64 &gt;&gt;&gt; s.index Index([&apos;a&apos;, &apos;b&apos;, &apos;c&apos;, &apos;d&apos;, &apos;e&apos;], dtype=&apos;object&apos;) &gt;&gt;&gt; pd.Series(np.random.randn(5)) 0 -0.467183 1 -1.333323 2 -0.493813 3 -0.067705 4 -1.310332 dtype: float64 需要注意的是: pandas里的索引并不要求唯一性，如果一个操作不支持重复的索引，会自动抛出异常。这么做的原因是很多操作不会用到索引，比如GroupBy。 &gt;&gt;&gt; s = pd.Series(np.random.randn(5), index=[&apos;a&apos;, &apos;a&apos;, &apos;a&apos;, &apos;a&apos;, &apos;a&apos;]) &gt;&gt;&gt; s a 0.847331 a -2.138021 a -0.364763 a -0.603172 a 0.363691 dtype: float64 使用dict创建(From dict)当data是dict类型时，如果指定了index参数，那么就使用index参数作为索引。否者，就使用排序后的data的key作为index。 &gt;&gt;&gt; d = {&apos;b&apos;: 0., &apos;a&apos;: 1., &apos;c&apos;: 2.} # 索引的值是排序后的 &gt;&gt;&gt; pd.Series(d) a 1.0 b 0.0 c 2.0 dtype: float64 # 字典中不存在的key, 直接赋值为NaN(Not a number) &gt;&gt;&gt; pd.Series(d, index=[&apos;b&apos;, &apos;c&apos;, &apos;d&apos;, &apos;a&apos;]) b 0.0 c 2.0 d NaN a 1.0 dtype: float64 使用标量创建(From scalar value)当data是标量时，必须提供index, 值会被重复到index的长度 &gt;&gt;&gt; pd.Series(5., index=[&apos;a&apos;, &apos;b&apos;, &apos;c&apos;, &apos;d&apos;, &apos;e&apos;]) a 5.0 b 5.0 c 5.0 d 5.0 e 5.0 dtype: float64 创建DataFrameDataFrame是一个二维的数据结构，可以看做是一个excel表格或一张SQL表，或者值为Series的字典。 跟Series一样，DataFrame也可以通过多种类型的数据结构来创建 字典(包含一维ndarray数组，列表，字典或Series) 二维的ndarray数组 结构化的ndarray Series 另一个DataFrame 除了data之外，还接受index和columns参数来分布指定行和列的标签 从Series字典或嵌套的字典创建(From dict of Series or dicts)结果的索引是多个Series索引的合集，如果没有指定columns，就用排序后的字典的key作为列标签。 &gt;&gt;&gt; d = {&apos;one&apos;: pd.Series([1,2,3], index=[&apos;a&apos;, &apos;b&apos;, &apos;c&apos;]), ... &apos;two&apos;: pd.Series([1,2,3,4], index=[&apos;a&apos;, &apos;b&apos;, &apos;c&apos;, &apos;d&apos;])} ... &gt;&gt;&gt; df = pd.DataFrame(d) &gt;&gt;&gt; df one two a 1.0 1 b 2.0 2 c 3.0 3 d NaN 4 &gt;&gt;&gt; pd.DataFrame(d, index=[&apos;d&apos;, &apos;b&apos;, &apos;a&apos;]) one two d NaN 4 b 2.0 2 a 1.0 1 &gt;&gt;&gt; pd.DataFrame(d, index=[&apos;d&apos;, &apos;b&apos;, &apos;a&apos;], columns=[&apos;two&apos;, &apos;three&apos;]) two three d 4 NaN b 2 NaN a 1 NaN &gt;&gt;&gt; df.index Index([&apos;a&apos;, &apos;b&apos;, &apos;c&apos;, &apos;d&apos;], dtype=&apos;object&apos;) &gt;&gt;&gt; df.columns Index([&apos;one&apos;, &apos;two&apos;], dtype=&apos;object&apos;) 从ndarray类型/列表类型的字典(From dict of ndarrays / lists)&gt;&gt;&gt; d = {&apos;one&apos;: [1,2,3,4], &apos;two&apos;: [4,3,2,1]} &gt;&gt;&gt; pd.DataFrame(d) one two 0 1 4 1 2 3 2 3 2 3 4 1 &gt;&gt;&gt; pd.DataFrame(d, index=[&apos;a&apos;, &apos;b&apos;, &apos;c&apos;, &apos;d&apos;]) one two a 1 4 b 2 3 c 3 2 d 4 1 从结构化ndarray创建(From structured or record array)&gt;&gt;&gt; data = np.zeros((2, ), dtype=[(&apos;A&apos;, &apos;i4&apos;), (&apos;B&apos;, &apos;f4&apos;), (&apos;C&apos;, &apos;a10&apos;)]) &gt;&gt;&gt; data array([(0, 0., b&apos;&apos;), (0, 0., b&apos;&apos;)], dtype=[(&apos;A&apos;, &apos;&lt;i4&apos;), (&apos;B&apos;, &apos;&lt;f4&apos;), (&apos;C&apos;, &apos;S10&apos;)]) &gt;&gt;&gt; data[:] = [(1, 2., &apos;Hello&apos;), (2, 3., &apos;World&apos;)] &gt;&gt;&gt; pd.DataFrame(data) A B C 0 1 2.0 b&apos;Hello&apos; 1 2 3.0 b&apos;World&apos; &gt;&gt;&gt; pd.DataFrame(data, index=[&apos;first&apos;, &apos;second&apos;]) A B C first 1 2.0 b&apos;Hello&apos; second 2 3.0 b&apos;World&apos; &gt;&gt;&gt; pd.DataFrame(data, index=[&apos;first&apos;, &apos;second&apos;], columns=[&apos;C&apos;, &apos;A&apos;, &apos;B&apos;]) C A B first b&apos;Hello&apos; 1 2.0 second b&apos;World&apos; 2 3.0 从字典列表里创建(a list of dicts)&gt;&gt;&gt; data2 = [{&quot;a&quot;: 1, &quot;b&quot;: 2}, {&quot;a&quot;: 5, &quot;b&quot;: 10, &quot;c&quot;: 20}] &gt;&gt;&gt; pd.DataFrame(data2) a b c 0 1 2 NaN 1 5 10 20.0 &gt;&gt;&gt; pd.DataFrame(data2, index=[&quot;first&quot;, &quot;second&quot;]) a b c first 1 2 NaN second 5 10 20.0 &gt;&gt;&gt; pd.DataFrame(data2, columns=[&quot;a&quot;, &quot;b&quot;]) a b 0 1 2 1 5 10 从元祖字典创建（From a dict of tuples）通过元祖字典，可以创建多索引的DataFrame &gt;&gt;&gt; pd.DataFrame({(&apos;a&apos;, &apos;b&apos;): {(&apos;A&apos;, &apos;B&apos;): 1, (&apos;A&apos;, &apos;C&apos;): 2}, ... (&apos;a&apos;, &apos;a&apos;): {(&apos;A&apos;, &apos;C&apos;): 3, (&apos;A&apos;, &apos;B&apos;): 4}, ... (&apos;a&apos;, &apos;c&apos;): {(&apos;A&apos;, &apos;B&apos;): 5, (&apos;A&apos;, &apos;C&apos;): 6}, ... (&apos;b&apos;, &apos;a&apos;): {(&apos;A&apos;, &apos;C&apos;): 7, (&apos;A&apos;, &apos;B&apos;): 8}, ... (&apos;b&apos;, &apos;b&apos;): {(&apos;A&apos;, &apos;D&apos;): 9, (&apos;A&apos;, &apos;B&apos;): 10}}) ... a b a b c a b A B 4.0 1.0 5.0 8.0 10.0 C 3.0 2.0 6.0 7.0 NaN D NaN NaN NaN NaN 9.0 通过Series创建(From a Series)&gt;&gt;&gt; pd.DataFrame(pd.Series([1,2,3])) 0 0 1 1 2 2 3 查看数据&gt;&gt;&gt; dates = pd.date_range(&apos;20130101&apos;, periods=6) &gt;&gt;&gt; dates DatetimeIndex([&apos;2013-01-01&apos;, &apos;2013-01-02&apos;, &apos;2013-01-03&apos;, &apos;2013-01-04&apos;, &apos;2013-01-05&apos;, &apos;2013-01-06&apos;], dtype=&apos;datetime64[ns]&apos;, freq=&apos;D&apos;) &gt;&gt;&gt; df = pd.DataFrame(np.random.randn(6,4),index=dates,columns=list(&apos;ABCD&apos;)) &gt;&gt;&gt; df A B C D 2013-01-01 1.231897 -0.169839 1.333295 0.367142 2013-01-02 -0.127450 -1.716671 0.910350 0.151186 2013-01-03 -0.241652 -0.984647 0.788656 -0.203639 2013-01-04 0.044990 -0.255158 -1.213848 1.076715 2013-01-05 0.418213 0.107400 0.619448 1.494087 2013-01-06 -1.831020 0.813526 0.403101 -1.251946 # 获取前几行(默认前5行) &gt;&gt;&gt; df.head() A B C D 2013-01-01 1.231897 -0.169839 1.333295 0.367142 2013-01-02 -0.127450 -1.716671 0.910350 0.151186 2013-01-03 -0.241652 -0.984647 0.788656 -0.203639 2013-01-04 0.044990 -0.255158 -1.213848 1.076715 2013-01-05 0.418213 0.107400 0.619448 1.494087 # 获取后3行 &gt;&gt;&gt; df.tail(3) A B C D 2013-01-04 0.044990 -0.255158 -1.213848 1.076715 2013-01-05 0.418213 0.107400 0.619448 1.494087 2013-01-06 -1.831020 0.813526 0.403101 -1.251946 # 获取索引 &gt;&gt;&gt; df.index DatetimeIndex([&apos;2013-01-01&apos;, &apos;2013-01-02&apos;, &apos;2013-01-03&apos;, &apos;2013-01-04&apos;, &apos;2013-01-05&apos;, &apos;2013-01-06&apos;], dtype=&apos;datetime64[ns]&apos;, freq=&apos;D&apos;) # 获取列信息 &gt;&gt;&gt; df.columns Index([&apos;A&apos;, &apos;B&apos;, &apos;C&apos;, &apos;D&apos;], dtype=&apos;object&apos;) # 获取数据信息 &gt;&gt;&gt; df.values array([[ 1.23189704, -0.16983942, 1.3332949 , 0.36714191], [-0.12744988, -1.71667129, 0.91034961, 0.15118638], [-0.24165226, -0.98464711, 0.78865554, -0.20363944], [ 0.04498958, -0.25515787, -1.21384804, 1.07671506], [ 0.41821265, 0.10740007, 0.61944799, 1.49408712], [-1.8310196 , 0.81352564, 0.40310115, -1.25194611]]) # 获取简单的统计信息 &gt;&gt;&gt; df.describe() A B C D count 6.000000 6.000000 6.000000 6.000000 mean -0.084170 -0.367565 0.473500 0.272257 std 1.007895 0.880134 0.883494 0.970912 min -1.831020 -1.716671 -1.213848 -1.251946 25% -0.213102 -0.802275 0.457188 -0.114933 50% -0.041230 -0.212499 0.704052 0.259164 75% 0.324907 0.038090 0.879926 0.899322 max 1.231897 0.813526 1.333295 1.494087 # 转置矩阵 &gt;&gt;&gt; df.T 2013-01-01 2013-01-02 2013-01-03 2013-01-04 2013-01-05 2013-01-06 A 1.231897 -0.127450 -0.241652 0.044990 0.418213 -1.831020 B -0.169839 -1.716671 -0.984647 -0.255158 0.107400 0.813526 C 1.333295 0.910350 0.788656 -1.213848 0.619448 0.403101 D 0.367142 0.151186 -0.203639 1.076715 1.494087 -1.251946 # 按照列排序 &gt;&gt;&gt; df.sort_values(by=&apos;B&apos;) A B C D 2013-01-02 -0.127450 -1.716671 0.910350 0.151186 2013-01-03 -0.241652 -0.984647 0.788656 -0.203639 2013-01-04 0.044990 -0.255158 -1.213848 1.076715 2013-01-01 1.231897 -0.169839 1.333295 0.367142 2013-01-05 0.418213 0.107400 0.619448 1.494087 2013-01-06 -1.831020 0.813526 0.403101 -1.251946 选择数据获取选择列， 返回的是Series &gt;&gt;&gt; df[&apos;A&apos;] 2013-01-01 1.231897 2013-01-02 -0.127450 2013-01-03 -0.241652 2013-01-04 0.044990 2013-01-05 0.418213 2013-01-06 -1.831020 Freq: D, Name: A, dtype: float64 &gt;&gt;&gt; df.A 2013-01-01 1.231897 2013-01-02 -0.127450 2013-01-03 -0.241652 2013-01-04 0.044990 2013-01-05 0.418213 2013-01-06 -1.831020 Freq: D, Name: A, dtype: float64 选择行 &gt;&gt;&gt; df[0:3] A B C D 2013-01-01 1.231897 -0.169839 1.333295 0.367142 2013-01-02 -0.127450 -1.716671 0.910350 0.151186 2013-01-03 -0.241652 -0.984647 0.788656 -0.203639 &gt;&gt;&gt; df[&quot;20130102&quot;:&quot;20130104&quot;] A B C D 2013-01-02 -0.127450 -1.716671 0.910350 0.151186 2013-01-03 -0.241652 -0.984647 0.788656 -0.203639 2013-01-04 0.044990 -0.255158 -1.213848 1.076715 通过Label选择# 返回的Series &gt;&gt;&gt; df.loc[dates[0]] A 1.231897 B -0.169839 C 1.333295 D 0.367142 Name: 2013-01-01 00:00:00, dtype: float64 # 返回的DateFrame &gt;&gt;&gt; df.loc[:, [&apos;A&apos;, &apos;B&apos;]] A B 2013-01-01 1.231897 -0.169839 2013-01-02 -0.127450 -1.716671 2013-01-03 -0.241652 -0.984647 2013-01-04 0.044990 -0.255158 2013-01-05 0.418213 0.107400 2013-01-06 -1.831020 0.813526 &gt;&gt;&gt; df.loc[&apos;20130102&apos;:&apos;20130104&apos;,[&apos;A&apos;,&apos;B&apos;]] A B 2013-01-02 -0.127450 -1.716671 2013-01-03 -0.241652 -0.984647 2013-01-04 0.044990 -0.255158 # 降维返回 &gt;&gt;&gt; df.loc[&apos;20130102&apos;,[&apos;A&apos;,&apos;B&apos;]] A -0.127450 B -1.716671 Name: 2013-01-02 00:00:00, dtype: float64 通过Position选择# 返回第4行 &gt;&gt;&gt; df.iloc[3] A 0.044990 B -0.255158 C -1.213848 D 1.076715 Name: 2013-01-04 00:00:00, dtype: float64 &gt;&gt;&gt; df.iloc[3:5,0:2] A B 2013-01-04 0.044990 -0.255158 2013-01-05 0.418213 0.107400 &gt;&gt;&gt; df.iloc[1:3, :] A B C D 2013-01-02 -0.127450 -1.716671 0.910350 0.151186 2013-01-03 -0.241652 -0.984647 0.788656 -0.203639 # 获得指定位置的元素 &gt;&gt;&gt; df.iloc[1,1] -1.7166712884342545 &gt;&gt;&gt; df.iat[1,1] -1.7166712884342545 布尔索引&gt;&gt;&gt; df[df.A &gt; 0] A B C D 2013-01-01 1.231897 -0.169839 1.333295 0.367142 2013-01-04 0.044990 -0.255158 -1.213848 1.076715 2013-01-05 0.418213 0.107400 0.619448 1.494087 &gt;&gt;&gt; df[df &gt; 0] A B C D 2013-01-01 1.231897 NaN 1.333295 0.367142 2013-01-02 NaN NaN 0.910350 0.151186 2013-01-03 NaN NaN 0.788656 NaN 2013-01-04 0.044990 NaN NaN 1.076715 2013-01-05 0.418213 0.107400 0.619448 1.494087 2013-01-06 NaN 0.813526 0.403101 NaN &gt;&gt;&gt; df2=df.copy() &gt;&gt;&gt; df2[&apos;E&apos;] = [&apos;one&apos;,&apos;one&apos;,&apos;two&apos;,&apos;three&apos;,&apos;four&apos;,&apos;three&apos;] &gt;&gt;&gt; df2 A B C D E 2013-01-01 1.231897 -0.169839 1.333295 0.367142 one 2013-01-02 -0.127450 -1.716671 0.910350 0.151186 one 2013-01-03 -0.241652 -0.984647 0.788656 -0.203639 two 2013-01-04 0.044990 -0.255158 -1.213848 1.076715 three 2013-01-05 0.418213 0.107400 0.619448 1.494087 four 2013-01-06 -1.831020 0.813526 0.403101 -1.251946 three # 使用isin()来过滤 &gt;&gt;&gt; df2[df2[&apos;E&apos;].isin([&apos;two&apos;, &apos;four&apos;])] A B C D E 2013-01-03 -0.241652 -0.984647 0.788656 -0.203639 two 2013-01-05 0.418213 0.107400 0.619448 1.494087 four 赋值根据日期新增加一列 &gt;&gt;&gt; s1 2013-01-02 1 2013-01-03 2 2013-01-04 3 2013-01-05 4 2013-01-06 5 2013-01-07 6 Freq: D, dtype: int64 &gt;&gt;&gt; df[&apos;F&apos;] = s1 &gt;&gt;&gt; df A B C D F 2013-01-01 1.231897 -0.169839 1.333295 0.367142 NaN 2013-01-02 -0.127450 -1.716671 0.910350 0.151186 1.0 2013-01-03 -0.241652 -0.984647 0.788656 -0.203639 2.0 2013-01-04 0.044990 -0.255158 -1.213848 1.076715 3.0 2013-01-05 0.418213 0.107400 0.619448 1.494087 4.0 2013-01-06 -1.831020 0.813526 0.403101 -1.251946 5.0 # 通过label赋值 &gt;&gt;&gt; df.at[dates[0], &apos;A&apos;] = 0 # 通过position赋值 &gt;&gt;&gt; df.iat[0,1] = 0 # 通过ndarray赋值 &gt;&gt;&gt; df.loc[:, &apos;D&apos;] = np.array([5] * len(df)) &gt;&gt;&gt; df A B C D F 2013-01-01 0.000000 0.000000 1.333295 5 NaN 2013-01-02 -0.127450 -1.716671 0.910350 5 1.0 2013-01-03 -0.241652 -0.984647 0.788656 5 2.0 2013-01-04 0.044990 -0.255158 -1.213848 5 3.0 2013-01-05 0.418213 0.107400 0.619448 5 4.0 2013-01-06 -1.831020 0.813526 0.403101 5 5.0 # 通过where操作 &gt;&gt;&gt; df = pd.DataFrame(np.random.randn(6,4),index=dates,columns=list(&apos;ABCD&apos;)) &gt;&gt;&gt; df A B C D 2013-01-01 -1.231777 -0.068987 -0.105402 1.512076 2013-01-02 -1.120426 -0.240417 0.223964 -0.559793 2013-01-03 0.697097 0.758780 -1.191408 -0.793882 2013-01-04 0.332519 0.784564 0.805932 -1.169186 2013-01-05 0.010235 0.156115 0.419567 -2.279214 2013-01-06 0.294819 -0.691370 0.294119 -0.208475 &gt;&gt;&gt; df2 = df.copy() &gt;&gt;&gt; df2[df &gt; 0] = -df2 &gt;&gt;&gt; df2 A B C D 2013-01-01 -1.231777 -0.068987 -0.105402 -1.512076 2013-01-02 -1.120426 -0.240417 -0.223964 -0.559793 2013-01-03 -0.697097 -0.758780 -1.191408 -0.793882 2013-01-04 -0.332519 -0.784564 -0.805932 -1.169186 2013-01-05 -0.010235 -0.156115 -0.419567 -2.279214 2013-01-06 -0.294819 -0.691370 -0.294119 -0.208475 数据缺失pandas使用np.nan来表示缺失的数据，它默认不参与任何运算 &gt;&gt;&gt; df1 = df.reindex(index=dates[0:4], columns=list(df.columns) + [&apos;E&apos;]) &gt;&gt;&gt; df1 A B C D F E 2013-01-01 0.000000 0.000000 1.333295 5 NaN NaN 2013-01-02 -0.127450 -1.716671 0.910350 5 1.0 NaN 2013-01-03 -0.241652 -0.984647 0.788656 5 2.0 NaN 2013-01-04 0.044990 -0.255158 -1.213848 5 3.0 NaN &gt;&gt;&gt; df1.loc[dates[0]:dates[1], &apos;E&apos;] = 1 &gt;&gt;&gt; df1 A B C D F E 2013-01-01 0.000000 0.000000 1.333295 5 NaN 1.0 2013-01-02 -0.127450 -1.716671 0.910350 5 1.0 1.0 2013-01-03 -0.241652 -0.984647 0.788656 5 2.0 NaN 2013-01-04 0.044990 -0.255158 -1.213848 5 3.0 NaN # 丢弃所有包含NaN的行 &gt;&gt;&gt; df1.dropna(how=&apos;any&apos;) A B C D F E 2013-01-02 -0.12745 -1.716671 0.91035 5 1.0 1.0 # 填充所有包含NaN的元素 &gt;&gt;&gt; df1.fillna(value=5) A B C D F E 2013-01-01 0.000000 0.000000 1.333295 5 5.0 1.0 2013-01-02 -0.127450 -1.716671 0.910350 5 1.0 1.0 2013-01-03 -0.241652 -0.984647 0.788656 5 2.0 5.0 2013-01-04 0.044990 -0.255158 -1.213848 5 3.0 5.0 # 获取元素值为nan的布尔掩码 &gt;&gt;&gt; pd.isna(df1) A B C D F E 2013-01-01 False False False False True False 2013-01-02 False False False False False False 2013-01-03 False False False False False True 2013-01-04 False False False False False True 运算操作Stats统计运算操作都会排除NaN元素 &gt;&gt;&gt; dates = pd.date_range(&apos;20130101&apos;, periods=6) &gt;&gt;&gt; df = pd.DataFrame(np.arange(24).reshape(6,4),index=dates,columns=list(&apos;ABCD&apos;)) &gt;&gt;&gt; df A B C D 2013-01-01 0 1 2 3 2013-01-02 4 5 6 7 2013-01-03 8 9 10 11 2013-01-04 12 13 14 15 2013-01-05 16 17 18 19 2013-01-06 20 21 22 23 # 计算列的平均值 &gt;&gt;&gt; df.mean() A 10.0 B 11.0 C 12.0 D 13.0 dtype: float64 计算行的平均值 &gt;&gt;&gt; df.mean(1) 2013-01-01 1.5 2013-01-02 5.5 2013-01-03 9.5 2013-01-04 13.5 2013-01-05 17.5 2013-01-06 21.5 Freq: D, dtype: float64 # shift(n),按照列的方向，从上往下移动n个位置 &gt;&gt;&gt; s = pd.Series([1,3,5,np.nan,6,8], index=dates).shift(2) &gt;&gt;&gt; s 2013-01-01 NaN 2013-01-02 NaN 2013-01-03 1.0 2013-01-04 3.0 2013-01-05 5.0 2013-01-06 NaN Freq: D, dtype: float64 # sub函数,DataFrame相减操作, 等于 df-s &gt;&gt;&gt; df.sub(s, axis=&apos;index&apos;) A B C D 2013-01-01 NaN NaN NaN NaN 2013-01-02 NaN NaN NaN NaN 2013-01-03 7.0 8.0 9.0 10.0 2013-01-04 9.0 10.0 11.0 12.0 2013-01-05 11.0 12.0 13.0 14.0 2013-01-06 NaN NaN NaN NaN Apply&gt;&gt;&gt; df A B C D 2013-01-01 0 1 2 3 2013-01-02 4 5 6 7 2013-01-03 8 9 10 11 2013-01-04 12 13 14 15 2013-01-05 16 17 18 19 2013-01-06 20 21 22 23 # 在列方向累加 &gt;&gt;&gt; df.apply(np.cumsum) A B C D 2013-01-01 0 1 2 3 2013-01-02 4 6 8 10 2013-01-03 12 15 18 21 2013-01-04 24 28 32 36 2013-01-05 40 45 50 55 2013-01-06 60 66 72 78 # 列方向的最大值-最小值， 得到的是一个Series &gt;&gt;&gt; df.apply(lambda x: x.max() - x.min()) A 20 B 20 C 20 D 20 dtype: int64 直方图 Histogramming&gt;&gt;&gt; s = pd.Series(np.random.randint(0, 7, size=10)) &gt;&gt;&gt; s 0 6 1 5 2 0 3 2 4 5 5 1 6 3 7 3 8 3 9 1 dtype: int64 # 索引是出现的数字，值是次数 &gt;&gt;&gt; s.value_counts() 3 3 5 2 1 2 6 1 2 1 0 1 dtype: int64 字符串方法&gt;&gt;&gt; s = pd.Series([&apos;A&apos;, &apos;B&apos;, &apos;C&apos;, &apos;Aaba&apos;, &apos;Baca&apos;, np.nan, &apos;CABA&apos;, &apos;dog&apos;, &apos;cat&apos;]) &gt;&gt;&gt; s.str.lower() 0 a 1 b 2 c 3 aaba 4 baca 5 NaN 6 caba 7 dog 8 cat dtype: object 合并Concat&gt;&gt;&gt; df = pd.DataFrame(np.random.randn(10, 4)) &gt;&gt;&gt; df 0 1 2 3 0 -1.710767 -2.107488 1.441790 0.959924 1 0.509422 0.099733 0.845039 0.232462 2 -0.609247 0.533162 -0.387640 0.668803 3 0.946219 -0.326805 1.245303 1.336090 4 -1.069114 0.755313 -1.003991 -0.327009 5 1.169418 -1.225637 -2.137500 1.766341 6 -1.751095 0.279439 0.018053 1.800435 7 -0.328828 -1.513893 1.879333 0.945217 8 2.440123 -0.260918 -0.232951 -1.337775 9 -0.876878 -1.153583 -1.487573 -1.509871 # 分成小块 &gt;&gt;&gt; pieces = [df[:3], df[3:7], df[7:]] # 合并 &gt;&gt;&gt; pd.concat(pieces) 0 1 2 3 0 -1.710767 -2.107488 1.441790 0.959924 1 0.509422 0.099733 0.845039 0.232462 2 -0.609247 0.533162 -0.387640 0.668803 3 0.946219 -0.326805 1.245303 1.336090 4 -1.069114 0.755313 -1.003991 -0.327009 5 1.169418 -1.225637 -2.137500 1.766341 6 -1.751095 0.279439 0.018053 1.800435 7 -0.328828 -1.513893 1.879333 0.945217 8 2.440123 -0.260918 -0.232951 -1.337775 9 -0.876878 -1.153583 -1.487573 -1.509871 Join跟数据库的Join操作一样 &gt;&gt;&gt; left = pd.DataFrame({&apos;key&apos;: [&apos;foo&apos;, &apos;foo&apos;], &apos;lval&apos;: [1, 2]}) &gt;&gt;&gt; left key lval 0 foo 1 1 foo 2 &gt;&gt;&gt; right = pd.DataFrame({&apos;key&apos;: [&apos;foo&apos;, &apos;foo&apos;], &apos;rval&apos;: [4, 5]}) &gt;&gt;&gt; right key rval 0 foo 4 1 foo 5 &gt;&gt;&gt; pd.merge(left, right, on=&apos;key&apos;) key lval rval 0 foo 1 4 1 foo 1 5 2 foo 2 4 3 foo 2 5 另一个例子 &gt;&gt;&gt; left = pd.DataFrame({&apos;key&apos;: [&apos;foo&apos;, &apos;bar&apos;], &apos;lval&apos;: [1, 2]}) &gt;&gt;&gt; left key lval 0 foo 1 1 bar 2 &gt;&gt;&gt; right = pd.DataFrame({&apos;key&apos;: [&apos;foo&apos;, &apos;bar&apos;], &apos;rval&apos;: [4, 5]}) &gt;&gt;&gt; right key rval 0 foo 4 1 bar 5 &gt;&gt;&gt; pd.merge(left, right, on=&apos;key&apos;) key lval rval 0 foo 1 4 1 bar 2 5 Append&gt;&gt;&gt; df = pd.DataFrame(np.random.randn(8, 4), columns=[&apos;A&apos;,&apos;B&apos;,&apos;C&apos;,&apos;D&apos;]) &gt;&gt;&gt; df A B C D 0 -1.521762 -0.850721 1.322354 -0.226562 1 -2.773304 -0.663303 0.895075 -0.171524 2 0.322975 -0.796484 0.379920 0.028333 3 -0.350795 1.839747 -0.359241 -0.027921 4 -0.945340 1.062598 -2.208670 0.769027 5 -0.329458 -0.145658 1.580258 -1.414820 6 -0.261757 -1.435025 -0.512306 -0.222287 7 -0.994207 -1.219057 0.781283 -1.795741 &gt;&gt;&gt; s = df.iloc[3] &gt;&gt;&gt; df.append(s, ignore_index=True) A B C D 0 -1.521762 -0.850721 1.322354 -0.226562 1 -2.773304 -0.663303 0.895075 -0.171524 2 0.322975 -0.796484 0.379920 0.028333 3 -0.350795 1.839747 -0.359241 -0.027921 4 -0.945340 1.062598 -2.208670 0.769027 5 -0.329458 -0.145658 1.580258 -1.414820 6 -0.261757 -1.435025 -0.512306 -0.222287 7 -0.994207 -1.219057 0.781283 -1.795741 8 -0.350795 1.839747 -0.359241 -0.027921 Groupinggroup by的操作需要经过以下1个或多个步骤 根据条件分组数据(Spliting) 在各个分组上执行函数(Applying) 合并结果(Combining) &gt;&gt;&gt; df = pd.DataFrame({&apos;A&apos; : [&apos;foo&apos;, &apos;bar&apos;, &apos;foo&apos;, &apos;bar&apos;, ... &apos;foo&apos;, &apos;bar&apos;, &apos;foo&apos;, &apos;foo&apos;], ... &apos;B&apos; : [&apos;one&apos;, &apos;one&apos;, &apos;two&apos;, &apos;three&apos;, ... &apos;two&apos;, &apos;two&apos;, &apos;one&apos;, &apos;three&apos;], ... &apos;C&apos; : np.arange(1, 9), ... &apos;D&apos; : np.arange(2, 10)}) ... ... &gt;&gt;&gt; df A B C D 0 foo one 1 2 1 bar one 2 3 2 foo two 3 4 3 bar three 4 5 4 foo two 5 6 5 bar two 6 7 6 foo one 7 8 7 foo three 8 9 # 分组求和 &gt;&gt;&gt; df.groupby(&apos;A&apos;).sum() C D A bar 12 15 foo 24 29 # 多列分组 &gt;&gt;&gt; df.groupby([&apos;A&apos;,&apos;B&apos;]).sum() C D A B bar one 2 3 three 4 5 two 6 7 foo one 8 10 three 8 9 two 8 10 &gt;&gt;&gt; b = df.groupby([&apos;A&apos;,&apos;B&apos;]).sum() # 多索引 &gt;&gt;&gt; b.index MultiIndex(levels=[[&apos;bar&apos;, &apos;foo&apos;], [&apos;one&apos;, &apos;three&apos;, &apos;two&apos;]], labels=[[0, 0, 0, 1, 1, 1], [0, 1, 2, 0, 1, 2]], names=[&apos;A&apos;, &apos;B&apos;]) &gt;&gt;&gt; b.columns Index([‘C’, ‘D’], dtype=’object’) ReshapingStack&gt;&gt;&gt; tuples = list(zip(*[[&apos;bar&apos;, &apos;bar&apos;, &apos;baz&apos;, &apos;baz&apos;, ... &apos;foo&apos;, &apos;foo&apos;, &apos;qux&apos;, &apos;qux&apos;], ... [&apos;one&apos;, &apos;two&apos;, &apos;one&apos;, &apos;two&apos;, ... &apos;one&apos;, &apos;two&apos;, &apos;one&apos;, &apos;two&apos;]])) ... &gt;&gt;&gt; tuples [(&apos;bar&apos;, &apos;one&apos;), (&apos;bar&apos;, &apos;two&apos;), (&apos;baz&apos;, &apos;one&apos;), (&apos;baz&apos;, &apos;two&apos;), (&apos;foo&apos;, &apos;one&apos;), (&apos;foo&apos;, &apos;two&apos;), (&apos;qux&apos;, &apos;one&apos;), (&apos;qux&apos;, &apos;two&apos;)] &gt;&gt;&gt; index = pd.MultiIndex.from_tuples(tuples, names=[&apos;first&apos;, &apos;second&apos;]) &gt;&gt;&gt; df = pd.DataFrame(np.random.randn(8, 2), index=index, columns=[&apos;A&apos;, &apos;B&apos;]) &gt;&gt;&gt; df A B first second bar one 0.096893 0.479194 two -0.771606 0.331693 baz one -0.022540 0.531284 two -0.039843 1.876942 foo one 0.250473 1.163931 two -1.127163 1.447566 qux one -0.410361 -0.734333 two -0.461247 0.018531 &gt;&gt;&gt; df2 = df[:4] &gt;&gt;&gt; df2 A B first second bar one 0.096893 0.479194 two -0.771606 0.331693 baz one -0.022540 0.531284 two -0.039843 1.876942 &gt;&gt;&gt; stacked = df2.stack() &gt;&gt;&gt; stacked first second bar one A 0.096893 B 0.479194 two A -0.771606 B 0.331693 baz one A -0.022540 B 0.531284 two A -0.039843 B 1.876942 dtype: float64 &gt;&gt;&gt; type(stacked) pandas.core.series.Series &gt;&gt;&gt; stacked.index MultiIndex(levels=[[&apos;bar&apos;, &apos;baz&apos;, &apos;foo&apos;, &apos;qux&apos;], [&apos;one&apos;, &apos;two&apos;], [&apos;A&apos;, &apos;B&apos;]], labels=[[0, 0, 0, 0, 1, 1, 1, 1], [0, 0, 1, 1, 0, 0, 1, 1], [0, 1, 0, 1, 0, 1, 0, 1]], names=[&apos;first&apos;, &apos;second&apos;, None]) &gt;&gt;&gt; stacked.values array([ 0.09689327, 0.47919417, -0.77160574, 0.3316934 , -0.02253955, 0.53128436, -0.03984337, 1.8769416 ]) &gt;&gt;&gt; stacked.unstack() A B first second bar one 0.096893 0.479194 two -0.771606 0.331693 baz one -0.022540 0.531284 two -0.039843 1.876942 &gt;&gt;&gt; stacked.unstack(1) second one two first bar A 0.096893 -0.771606 B 0.479194 0.331693 baz A -0.022540 -0.039843 B 0.531284 1.876942 &gt;&gt;&gt; stacked.unstack(0) first bar baz second one A 0.096893 -0.022540 B 0.479194 0.531284 two A -0.771606 -0.039843 B 0.331693 1.876942 数据透视表(Pivot Tables)时间序列pandas在时间序列上，提供了很方便的按照频率重新采样的功能，在财务分析上非常有用 # 把每秒的数据按5分钟聚合 &gt;&gt;&gt; rng = pd.date_range(&apos;1/1/2012&apos;, periods=100, freq=&apos;S&apos;) &gt;&gt;&gt; ts = pd.Series(np.random.randint(0, 500, len(rng)), index=rng) &gt;&gt;&gt; ts.resample(&apos;5Min&apos;).sum() 2012-01-01 22073 Freq: 5T, dtype: int64 加上时区信息 &gt;&gt;&gt; rng = pd.date_range(&apos;3/6/2012 00:00&apos;, periods=5, freq=&apos;D&apos;) &gt;&gt;&gt; ts = pd.Series(np.random.randn(len(rng)), rng) &gt;&gt;&gt; ts 2012-03-06 -0.386974 2012-03-07 0.657785 2012-03-08 1.390234 2012-03-09 0.412904 2012-03-10 -1.189340 Freq: D, dtype: float64 &gt;&gt;&gt; ts_utc = ts.tz_localize(&apos;UTC&apos;) &gt;&gt;&gt; ts_utc 2012-03-06 00:00:00+00:00 -0.386974 2012-03-07 00:00:00+00:00 0.657785 2012-03-08 00:00:00+00:00 1.390234 2012-03-09 00:00:00+00:00 0.412904 2012-03-10 00:00:00+00:00 -1.189340 Freq: D, dtype: float64 转换成另一个时区 &gt;&gt;&gt; ts_utc.tz_convert(&apos;Asia/Shanghai&apos;) 2012-03-06 08:00:00+08:00 -0.386974 2012-03-07 08:00:00+08:00 0.657785 2012-03-08 08:00:00+08:00 1.390234 2012-03-09 08:00:00+08:00 0.412904 2012-03-10 08:00:00+08:00 -1.189340 Freq: D, dtype: float64 时间跨度转换 &gt;&gt;&gt; rng = pd.date_range(&apos;1/1/2012&apos;, periods=5, freq=&apos;M&apos;) &gt;&gt;&gt; ts = pd.Series(np.random.randn(len(rng)), index=rng) &gt;&gt;&gt; ts 2012-01-31 0.825174 2012-02-29 -2.190258 2012-03-31 -0.073171 2012-04-30 -0.404208 2012-05-31 0.245025 Freq: M, dtype: float64 &gt;&gt;&gt; ps = ts.to_period() &gt;&gt;&gt; ps 2012-01 0.825174 2012-02 -2.190258 2012-03 -0.073171 2012-04 -0.404208 2012-05 0.245025 Freq: M, dtype: float64 &gt;&gt;&gt; ps.to_timestamp() 2012-01-01 0.825174 2012-02-01 -2.190258 2012-03-01 -0.073171 2012-04-01 -0.404208 2012-05-01 0.245025 Freq: MS, dtype: float64 转换季度时间 &gt;&gt;&gt; prng = pd.period_range(&apos;1990Q1&apos;, &apos;2000Q4&apos;, freq=&apos;Q-NOV&apos;) &gt;&gt;&gt; ts = pd.Series(np.random.randn(len(prng)), prng) &gt;&gt;&gt; ts.head() 1990Q1 -0.590040 1990Q2 -0.750392 1990Q3 -0.385517 1990Q4 -0.380806 1991Q1 -1.252727 Freq: Q-NOV, dtype: float64 &gt;&gt;&gt; ts.index = (prng.asfreq(&apos;M&apos;, &apos;e&apos;) + 1).asfreq(&apos;H&apos;, &apos;s&apos;) + 9 &gt;&gt;&gt; ts.head() 1990-03-01 09:00 -0.590040 1990-06-01 09:00 -0.750392 1990-09-01 09:00 -0.385517 1990-12-01 09:00 -0.380806 1991-03-01 09:00 -1.252727 Freq: H, dtype: float64 Categoricals分类&gt;&gt;&gt; df = pd.DataFrame({&quot;id&quot;:[1,2,3,4,5,6], &quot;raw_grade&quot;:[&apos;a&apos;, &apos;b&apos;, &apos;b&apos;, &apos;a&apos;, &apos;a&apos;, &apos;e&apos;]}) &gt;&gt;&gt; df id raw_grade 0 1 a 1 2 b 2 3 b 3 4 a 4 5 a 5 6 e 转换原始类别为分类数据类型 &gt;&gt;&gt; df[&quot;grade&quot;] = df[&quot;raw_grade&quot;].astype(&quot;category&quot;) &gt;&gt;&gt; df id raw_grade grade 0 1 a a 1 2 b b 2 3 b b 3 4 a a 4 5 a a 5 6 e e &gt;&gt;&gt; df[&quot;grade&quot;] 0 a 1 b 2 b 3 a 4 a 5 e Name: grade, dtype: category Categories (3, object): [a, b, e] 重命名分类为更有意义的名称 &gt;&gt;&gt; df[&quot;grade&quot;].cat.categories = [&quot;very good&quot;, &quot;good&quot;, &quot;very bad&quot;] &gt;&gt;&gt; df id raw_grade grade 0 1 a very good 1 2 b good 2 3 b good 3 4 a very good 4 5 a very good 5 6 e very bad 重新安排顺分类,同时添加缺少的分类(序列 .cat方法下返回新默认序列) &gt;&gt;&gt; df[&quot;grade&quot;] = df[&quot;grade&quot;].cat.set_categories([&quot;very bad&quot;, &quot;bad&quot;, &quot;medium&quot;, &quot;good&quot;, &quot;very good&quot;]) &gt;&gt;&gt; df id raw_grade grade 0 1 a very good 1 2 b good 2 3 b good 3 4 a very good 4 5 a very good 5 6 e very bad &gt;&gt;&gt; df[&quot;grade&quot;] 0 very good 1 good 2 good 3 very good 4 very good 5 very bad Name: grade, dtype: category Categories (5, object): [very bad, bad, medium, good, very good] 按照分类排序 &gt;&gt;&gt; df.sort_values(by=&quot;grade&quot;) id raw_grade grade 5 6 e very bad 1 2 b good 2 3 b good 0 1 a very good 3 4 a very good 4 5 a very good 按照分类分组，同时也会显示空的分类 &gt;&gt;&gt; df.groupby(&quot;grade&quot;).size() grade very bad 1 bad 0 medium 0 good 2 very good 3 dtype: int64 Plotting&gt;&gt;&gt; import matplotlib.pyplot as plt &gt;&gt;&gt; ts = pd.Series(np.random.randn(1000), index=pd.date_range(&apos;1/1/2000&apos;, periods=1000)) &gt;&gt;&gt; ts = ts.cumsum() &gt;&gt;&gt; ts.plot() &lt;matplotlib.axes._subplots.AxesSubplot at 0x108594668&gt; &gt;&gt;&gt; plt.show() 画图带图例的图 &gt;&gt;&gt; df = pd.DataFrame(np.random.randn(1000, 4), index=ts.index, columns=[&apos;A&apos;,&apos;B&apos; ... ,&apos;C&apos;, &apos;D&apos;]) &gt;&gt;&gt; df.cumsum() &gt;&gt;&gt; plt.figure();df.plot();plt.legend(loc=&apos;best&apos;) &lt;matplotlib.legend.Legend at 0x111793f98&gt; &gt;&gt;&gt; plt.show() 数据In/OutCSV保存到csv文件 &gt;&gt;&gt; df.to_csv(&apos;foo.csv&apos;) 从csv文件读取数据 &gt;&gt;&gt; pd.read_csv(&apos;foo.csv&apos;) HDF5保存到HDF5仓库 &gt;&gt;&gt; df.to_hdf(&apos;foo.h5&apos;,&apos;df&apos;) 从仓库读取 &gt;&gt;&gt; pd.read_hdf(&apos;foo.h5&apos;,&apos;df&apos;) Excel保存到excel &gt;&gt;&gt; df.to_excel(&apos;foo.xlsx&apos;, sheet_name=&apos;Sheet1&apos;) 从excel文件读取 &gt;&gt;&gt; pd.read_excel(&apos;foo.xlsx&apos;, &apos;Sheet1&apos;, index_col=None, na_values=[&apos;NA&apos;]) ## 扩展阅读 pandas指南]]></content>
      <categories>
        <category>python数据分析</category>
      </categories>
      <tags>
        <tag>pandas</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[NumPy快速入门指南.md]]></title>
    <url>%2F2017%2F12%2F19%2Fnumpy-qucikstart%2F</url>
    <content type="text"><![CDATA[参考:https://docs.scipy.org/doc/numpy-dev/user/quickstart.html 准备安装numpy $ pip install numpy 基础 In NumPy dimensions are called axes. The number of axes is rank. Numpy中，维度被称作axes, 维度数被称作rank。 Numpy的数组类是ndarray, 与标准python库的数组不太一样，它包含的元素必须是相同类型的。 ndarray的常见属性如下: ndarray.ndim数组的轴数(即rank) ndarray.shape数组的维度，返回的是一个元组，元组的长度值刚好是ndim ndarray.size数组元素的个数 ndarray.dtype数组元素的类型 ndarray.itemsize数组元素的字节大小 ndarray.data数组包含的实际数据(一般情况下不会用到这个属性，都是通过索引来访问元素) 数组例子&gt;&gt;&gt; import numpy as np &gt;&gt;&gt; a = np.arange(15).reshape(3,5) &gt;&gt;&gt; a array([[ 0, 1, 2, 3, 4], [ 5, 6, 7, 8, 9], [10, 11, 12, 13, 14]]) &gt;&gt;&gt; type(a) numpy.ndarray &gt;&gt;&gt; a.ndim 2 &gt;&gt;&gt; a.shape (3, 5) &gt;&gt;&gt; a.size 15 &gt;&gt;&gt; a.dtype dtype(&apos;int64&apos;) &gt;&gt;&gt; a.itemsize 8 &gt;&gt;&gt; a.data &lt;memory at 0x11221b120&gt; 创建数组创建数组一般有如下几种方法: 通过array函数，可以从普通的python列表或元组来创建 &gt;&gt;&gt; a=np.array([2,3,4]) &gt;&gt;&gt; a array([2, 3, 4]) &gt;&gt;&gt; a.dtype dtype(&apos;int64&apos;) &gt;&gt;&gt; b = np.array([1.2, 3.5, 5.1]) &gt;&gt;&gt; b.dtype dtype(&apos;float64&apos;) 一个常见的错误就是在调用array函数时， 传递多个参数，而不是一个列表 &gt;&gt;&gt; a = np.array(1,2,3,4) # 错误 &gt;&gt;&gt; a = np.array([1,2,3,4]) # 正确 array同样可以接受列表序列并将它转换为多维数组 &gt;&gt;&gt; c = np.array([(1.5, 2.3), (4,5,6)]) &gt;&gt;&gt; c array([(1.5, 2.3), (4, 5, 6)], dtype=object) 同样可以在创建数组的时候，指定数据类型 &gt;&gt;&gt; d = np.array([[1,2], [3,4]], dtype=complex) &gt;&gt;&gt; d array([[ 1.+0.j, 2.+0.j], [ 3.+0.j, 4.+0.j]]) 通常情况下， 数组元素的初始数据是不知道的，但是知道数组的大小。因此Numpy提供了一些函数来创建指定大小的数组，并用占位符来填充数组。 zeros函数创建初始值为0的数组 ones创建初始值为1的数组 empty创建未初始化的随机数组 默认情况下，上面三个函数创建数组的元素类型都是float64。 &gt;&gt;&gt; np.zeros((3,4)) array([[ 0., 0., 0., 0.], [ 0., 0., 0., 0.], [ 0., 0., 0., 0.]]) &gt;&gt;&gt; np.ones((3,4)) array([[ 1., 1., 1., 1.], [ 1., 1., 1., 1.], [ 1., 1., 1., 1.]]) &gt;&gt;&gt; np.empty((2,5)) array([[ 2.68156159e+154, 2.68679227e+154, 2.37663529e-312, 2.56761491e-312, 8.48798317e-313], [ 9.33678148e-313, 8.70018275e-313, 2.02566915e-322, 0.00000000e+000, 6.95335581e-309]]) 为了创建序列函数，Numpy也提供了类似range函数的方法 &gt;&gt;&gt; np.arange(10, 30, 5) array([10, 15, 20, 25]) &gt;&gt;&gt; np.arange(0, 2, 0.3) array([ 0. , 0.3, 0.6, 0.9, 1.2, 1.5, 1.8]) 当使用arange函数的生成float类型的序列时，生成的序列有时候并不会按照我们预期的步长来生成，要实现这个效果，最好是用linspace函数来代替。例如: &gt;&gt;&gt; from numpy import pi &gt;&gt;&gt; np.linspace(0, 2, 9) array([ 0. , 0.25, 0.5 , 0.75, 1. , 1.25, 1.5 , 1.75, 2. ]) &gt;&gt;&gt; x = np.linspace( 0, 2*pi, 100 ) &gt;&gt;&gt; f=np.sin(x) 除此之外，还可以使用下面的函数来创建数组 array zeros zeros_like # 创建一个和给定数组相同shape的全是0的数组 ones ones_like empty empty_like arange linspace numpy.random.rand # 从 [0, 1) 中返回一个或多个样本值。 numpy.random.randn # 从标准正态分布中返回一个或多个样本值。 fromfunction fromfile 打印数组当使用print函数打印数组时，numpy会输出一个嵌套的列表形式 # 一维数组 &gt;&gt;&gt; a = np.arange(6) &gt;&gt;&gt; print(a) [0 1 2 3 4 5] # 二维数组 &gt;&gt;&gt; b = np.arange(12).reshape(4,3) &gt;&gt;&gt; print(b) [[ 0 1 2] [ 3 4 5] [ 6 7 8] [ 9 10 11]] # 三维数组 &gt;&gt;&gt; c = np.arange(24).reshape(2,3,4) &gt;&gt;&gt; print(c) [[[ 0 1 2 3] [ 4 5 6 7] [ 8 9 10 11]] [[12 13 14 15] [16 17 18 19] [20 21 22 23]]] 当数组包含的元素太多时，会省略中间的元素，只打印角落的元素 &gt;&gt;&gt; print(np.arange(10000)) [ 0 1 2 ..., 9997 9998 9999] &gt;&gt;&gt; print(np.arange(10000).reshape(100,100)) [[ 0 1 2 ..., 97 98 99] [ 100 101 102 ..., 197 198 199] [ 200 201 202 ..., 297 298 299] ..., [9700 9701 9702 ..., 9797 9798 9799] [9800 9801 9802 ..., 9897 9898 9899] [9900 9901 9902 ..., 9997 9998 9999]] 如果想禁用这个行为，强制打印所有的元素，可以开启set_printoptions选项 &gt;&gt;&gt; np.set_printoptions(threshold=np.nan) &gt;&gt;&gt; print(np.arange(100)) [ 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99] 还原成省略效果 &gt;&gt;&gt; np.set_printoptions(threshold=1000) 设置打印浮点数的小数位数: np.set_printoptions(precision=4) # 设置打印浮点数的小数位数，默认是8位 基本操作数组的算术运算会自动作用于每个元素，并返回一个新的数组 &gt;&gt;&gt; a = np.array([20,30,40,50]) &gt;&gt;&gt; b = np.arange(4) &gt;&gt;&gt; c = a - b &gt;&gt;&gt; c array([20, 29, 38, 47]) &gt;&gt;&gt; b**2 array([0, 1, 4, 9]) &gt;&gt;&gt; 10 * np.sin(a) array([ 9.12945251, -9.88031624, 7.4511316 , -2.62374854]) &gt;&gt;&gt; a &lt; 35 array([ True, True, False, False], dtype=bool) *返回的是每个元素相乘的结果，要实现矩阵乘法，需要使用dot函数 &gt;&gt;&gt; a = np.array([ [1, 1], ... [0, 1]]) ... &gt;&gt;&gt; b = np.array([ [2, 0], ... [3, 4]]) ... &gt;&gt;&gt; a * b # 对应位置的元素相乘 array([[2, 0], [0, 4]]) &gt;&gt;&gt; a.dot(b) # 矩阵乘法 array([[5, 4], [3, 4]]) &gt;&gt;&gt; np.dot(a, b) # 另一种形式的矩阵乘法 array([[5, 4], [3, 4]]) 一些操作， 如+=和*=是直接修改原有的数组，而不是新建一个 &gt;&gt;&gt; a = np.ones((2,3), dtype=int) &gt;&gt;&gt; a array([[1, 1, 1], [1, 1, 1]]) &gt;&gt;&gt; b = np.random.random((2,3)) &gt;&gt;&gt; b array([[ 0.7216234 , 0.5813183 , 0.21175569], [ 0.11697569, 0.89835328, 0.06088455]]) &gt;&gt;&gt; a.dtype dtype(&apos;int64&apos;) &gt;&gt;&gt; b.dtype dtype(&apos;float64&apos;) &gt;&gt;&gt; b+=a &gt;&gt;&gt; b array([[ 1.7216234 , 1.5813183 , 1.21175569], [ 1.11697569, 1.89835328, 1.06088455]]) # 报错的原因是因为a数组原来是保存int64类型，现在没法保存float64类型 &gt;&gt;&gt; a+=b --------------------------------------------------------------------------- TypeError Traceback (most recent call last) &lt;ipython-input-11-0a45668e3cc6&gt; in &lt;module&gt;() ----&gt; 1 a+=b TypeError: Cannot cast ufunc add output from dtype(&apos;float64&apos;) to dtype(&apos;int64&apos;) with casting rule &apos;same_kind&apos; 当不同类型的数组运算操作时，总是向精度更高的自动转换 &gt;&gt;&gt; a = np.ones(3, dtype=np.int32) &gt;&gt;&gt; b = np.linspace(0, np.pi, 3) &gt;&gt;&gt; b.dtype.name &apos;float64&apos; &gt;&gt;&gt; c = a + b &gt;&gt;&gt; c array([ 1. , 2.57079633, 4.14159265]) &gt;&gt;&gt; c.dtype.name &apos;float64&apos; &gt;&gt;&gt; d = np.exp(c*1j) &gt;&gt;&gt; d array([ 0.54030231+0.84147098j, -0.84147098+0.54030231j, -0.54030231-0.84147098j]) &gt;&gt;&gt; d.dtype.name &apos;complex128&apos; ndarray包含了很多一元运算。如求和等 &gt;&gt;&gt; a = np.arange(15).reshape(3, 5) &gt;&gt;&gt; a array([[ 0, 1, 2, 3, 4], [ 5, 6, 7, 8, 9], [10, 11, 12, 13, 14]]) &gt;&gt;&gt; a.sum() 105 &gt;&gt;&gt; a.min() 0 &gt;&gt;&gt; a.max() 14 默认情况下，这些操作都是作用于每一个元素，而不管它的维度。但是，我们也可以通过axis参数来限定操作的轴 &gt;&gt;&gt; b = np.arange(12).reshape(3, 4) &gt;&gt;&gt; b array([[ 0, 1, 2, 3], [ 4, 5, 6, 7], [ 8, 9, 10, 11]]) # 计算每一列的和 &gt;&gt;&gt; b.sum(axis=0) array([12, 15, 18, 21]) # 计算每一行的最小值 &gt;&gt;&gt; b.min(axis=1) array([0, 4, 8]) # 每一行累积和 &gt;&gt;&gt; b.cumsum(axis=1) array([[ 0, 1, 3, 6], [ 4, 9, 15, 22], [ 8, 17, 27, 38]]) 通用函数Numpy提供了很多常见的数学上的运算，如sin, cos, exp。在Numpy中，我们称这些为”universal functions”（ufunc） &gt;&gt;&gt; B = np.arange(3) &gt;&gt;&gt; B array([0, 1, 2]) &gt;&gt;&gt; np.exp(B) array([ 1. , 2.71828183, 7.3890561 ]) &gt;&gt;&gt; 2.71828183 * 2.71828183 7.389056107308149 &gt;&gt;&gt; np.sqrt(B) array([ 0. , 1. , 1.41421356]) &gt;&gt;&gt; C = np.array([2., -1., 4.]) &gt;&gt;&gt; np.add(B, C) array([ 2., 0., 6.]) 索引，切片和迭代一维数组的索引，切片，迭代跟普通的python列表一样 &gt;&gt;&gt; a = np.arange(10) ** 3 &gt;&gt;&gt; a array([ 0, 1, 8, 27, 64, 125, 216, 343, 512, 729]) &gt;&gt;&gt; a[2] 8 &gt;&gt;&gt; a[2:5] array([ 8, 27, 64]) &gt;&gt;&gt; a[:6:2] # 等价于a[0:6:2] array([ 0, 8, 64]) &gt;&gt;&gt; a[:6:2] = -1000 &gt;&gt;&gt; a array([-1000, 1, -1000, 27, -1000, 125, 216, 343, 512, 729]) &gt;&gt;&gt; a[::-1] # 反转数组a array([ 729, 512, 343, 216, 125, -1000, 27, -1000, 1, -1000]) &gt;&gt;&gt; for i in a: ... print(i**(1/3.)) ... nan 1.0 nan 3.0 nan 5.0 6.0 7.0 8.0 9.0 多维数组可以在每个轴上索引，多个索引用,分隔 &gt;&gt;&gt; def f(x,y): ... return 10*x +y ... &gt;&gt;&gt; b=np.fromfunction(f, (5,4), dtype=int) &gt;&gt;&gt; b array([[ 0, 1, 2, 3], [10, 11, 12, 13], [20, 21, 22, 23], [30, 31, 32, 33], [40, 41, 42, 43]]) &gt;&gt;&gt; help(np.fromfunction) &gt;&gt;&gt; b[2,3] 23 &gt;&gt;&gt; b[0:5, 1] array([ 1, 11, 21, 31, 41]) &gt;&gt;&gt; b[:, 1] array([ 1, 11, 21, 31, 41]) &gt;&gt;&gt; b[1:3, :] array([[10, 11, 12, 13], [20, 21, 22, 23]]) 当索引数少于轴数时，缺失的索引认为是全切片: &gt;&gt;&gt; b[-1] # 等价于 b[-1,:] array([40, 41, 42, 43]) 同样可以使用...来表示全切片，它代表补全剩下的所有索引。例如数组x, rank是5.那么 x[1,2,...]等价于x[1,2,:,:,:] x[...,3]等价于x[:,:,:,:,3] x[4,...,5,:]等价于x[4,:,:,5,:] &gt;&gt;&gt; c = np.array([[[0,1,2], ... [10,12,13]], ... [[100,101,102], ... [110,112,113]]]) ... &gt;&gt;&gt; c.shape (2, 2, 3) &gt;&gt;&gt; c[1,...] array([[100, 101, 102], [110, 112, 113]]) &gt;&gt;&gt; c[...,2] array([[ 2, 13], [102, 113]]) 多维数组的迭代是根据第一个轴来操作的 &gt;&gt;&gt; b array([[ 0, 1, 2, 3], [10, 11, 12, 13], [20, 21, 22, 23], [30, 31, 32, 33], [40, 41, 42, 43]]) &gt;&gt;&gt; for row in b: ... print(row) ... [0 1 2 3] [10 11 12 13] [20 21 22 23] [30 31 32 33] [40 41 42 43] 如果想遍历每个元素，可以使用flat属性 &gt;&gt;&gt; for element in b.flat: ... print(element) ... 0 1 2 3 10 11 12 13 20 21 22 23 30 31 32 33 40 41 42 43 shape操作改变数组的shape许多函数都可以改变数组的shape，但是它们都是返回一个新的修改后的数组，并不会改变原数组 &gt;&gt;&gt; a = np.floor(10*np.random.random((3,4))) &gt;&gt;&gt; a.shape (3, 4) &gt;&gt;&gt; a array([[ 7., 8., 0., 9.], [ 8., 4., 9., 8.], [ 4., 3., 7., 0.]]) # 返回降维的数组 &gt;&gt;&gt; a.ravel() array([ 7., 8., 0., 9., 8., 4., 9., 8., 4., 3., 7., 0.]) # 直接修改shape &gt;&gt;&gt; a.reshape(6,2) array([[ 7., 8.], [ 0., 9.], [ 8., 4.], [ 9., 8.], [ 4., 3.], [ 7., 0.]]) # 数组转置 &gt;&gt;&gt; a.T array([[ 7., 8., 4.], [ 8., 4., 3.], [ 0., 9., 7.], [ 9., 8., 0.]]) &gt;&gt;&gt; a.T.shape (4, 3) &gt;&gt;&gt; a.shape (3, 4) reshape返回修改后的数组，不改变数组本身，但是resize函数直接修改原数组 &gt;&gt;&gt; a array([[ 7., 8., 0., 9.], [ 8., 4., 9., 8.], [ 4., 3., 7., 0.]]) &gt;&gt;&gt; a.resize((2,6)) &gt;&gt;&gt; a array([[ 7., 8., 0., 9., 8., 4.], [ 9., 8., 4., 3., 7., 0.]]) 如果一个维度为的是-1, 那么reshape函数会自动计算它的值。 &gt;&gt;&gt; a array([[ 7., 8., 0., 9., 8., 4.], [ 9., 8., 4., 3., 7., 0.]]) &gt;&gt;&gt; a.reshape(3, -1) array([[ 7., 8., 0., 9.], [ 8., 4., 9., 8.], [ 4., 3., 7., 0.]]) 数组合并多个数组可以根据不同的轴组合在一起 &gt;&gt;&gt; a = np.floor(10*np.random.random((2,2))) &gt;&gt;&gt; a array([[ 1., 1.], [ 4., 4.]]) &gt;&gt;&gt; b = np.floor(10*np.random.random((2,2))) &gt;&gt;&gt; b array([[ 2., 9.], [ 0., 3.]]) &gt;&gt;&gt; np.vstack((a, b)) array([[ 1., 1.], [ 4., 4.], [ 2., 9.], [ 0., 3.]]) &gt;&gt;&gt; np.hstack((a,b)) array([[ 1., 1., 2., 9.], [ 4., 4., 0., 3.]]) column_stack函数把1维数组当做列来拼成2维数组，如果只是操作2维数组，跟hstack的等效。 &gt;&gt;&gt; a array([[ 1., 1.], [ 4., 4.]]) &gt;&gt;&gt; b array([[ 2., 9.], [ 0., 3.]]) # 操作2维数组，等效于hstack &gt;&gt;&gt; np.column_stack((a, b)) array([[ 1., 1., 2., 9.], [ 4., 4., 0., 3.]]) &gt;&gt;&gt; a = np.array([4., 2.]) &gt;&gt;&gt; b = np.array([3., 8.]) # 操作1维数组，返回2维数组，a,b分别为2维数组的列 &gt;&gt;&gt; np.column_stack((a, b)) array([[ 4., 3.], [ 2., 8.]]) &gt;&gt;&gt; from numpy import newaxis # 将1维数组变成2维数组 &gt;&gt;&gt; a[:,newaxis] array([[ 4.], [ 2.]]) # 都是操作二维数组，下面两个操作column_stack和hstack等效 &gt;&gt;&gt; np.column_stack((a[:, newaxis], b[:, newaxis])) array([[ 4., 3.], [ 2., 8.]]) &gt;&gt;&gt; np.hstack((a[:, newaxis], b[:, newaxis])) array([[ 4., 3.], [ 2., 8.]]) 另外不论什么数组，row_stack函数等效于vstack。通常来说，2维以上的数组，hstack基于第2根轴做运算，vstack基于第1根轴，concatenate函数额外多接受一个参数，可以指定基于哪根轴做数组的合并操作。 另外, r_和c_函数对于在一个轴上组合数据相当哟偶用，他们允许使用范围符号: &gt;&gt;&gt; np.r_[1:4, 0, 4] array([1, 2, 3, 0, 4]) 数组切割使用hsplit函数，你可以在水平方向切割一个数组 &gt;&gt;&gt; a array([[ 9., 0., 2., 0., 0., 4., 1., 6., 4., 8., 3., 9.], [ 5., 3., 0., 5., 5., 8., 0., 5., 6., 3., 8., 7.]]) # 切割成3个数组 &gt;&gt;&gt; np.hsplit(a, 3) [array([[ 9., 0., 2., 0.], [ 5., 3., 0., 5.]]), array([[ 0., 4., 1., 6.], [ 5., 8., 0., 5.]]), array([[ 4., 8., 3., 9.], [ 6., 3., 8., 7.]])] &gt;&gt;&gt; np.vsplit(a, 2) [array([[ 9., 0., 2., 0., 0., 4., 1., 6., 4., 8., 3., 9.]]), array([[ 5., 3., 0., 5., 5., 8., 0., 5., 6., 3., 8., 7.]])] # 基于第3和第4列切割 &gt;&gt;&gt; np.hsplit(a, (3,4)) [array([[ 9., 0., 2.], [ 5., 3., 0.]]), array([[ 0.], [ 5.]]), array([[ 0., 4., 1., 6., 4., 8., 3., 9.], [ 5., 8., 0., 5., 6., 3., 8., 7.]])] vsplit可以基于垂直轴切割，array_split可以指定基于哪个轴切割 复制和视图(Views)当进行数组运算和改变数组时，有时候数据是被复制到一个新的数组，有时候不是。对于初学者来说，对于具体是哪种操作，很容易混淆。 主要分三种情况。 一点也不复制&gt;&gt;&gt; a = np.arange(12) &gt;&gt;&gt; b = a # 不会有新对象产生 &gt;&gt;&gt; b is a # a和b是同一个数组 True &gt;&gt;&gt; b.shape (12,) &gt;&gt;&gt; b.shape = 3, 4 # 改变b的shape, a也同样变化 &gt;&gt;&gt; a.shape (3, 4) &gt;&gt;&gt; a array([[ 0, 1, 2, 3], [ 4, 5, 6, 7], [ 8, 9, 10, 11]]) python中使用可变参数时，可以看做是引用传参，因此函数条用会产生新的数组 &gt;&gt;&gt; def f(x): ... print(id(x)) ... &gt;&gt;&gt; id(a) 4361164320 &gt;&gt;&gt; f(a) 4361164320 视图(View)和浅复制(Shallow Copy)不同的数组可以共享数据，view函数可以创造一个数据相同的新数组 &gt;&gt;&gt; a array([[ 0, 1, 2, 3], [ 4, 5, 6, 7], [ 8, 9, 10, 11]]) &gt;&gt;&gt; c = a.view() &gt;&gt;&gt; c is a # c和a不是同一个数组 False &gt;&gt;&gt; c.base is a # c是a的数据的视图 True &gt;&gt;&gt; c.flags.owndata False &gt;&gt;&gt; c.shape = 2, 6 # a的不会改变 &gt;&gt;&gt; a.shape (3, 4) &gt;&gt;&gt; c[0, 4] = 1234 # a的数据发生改变 &gt;&gt;&gt; a array([[ 0, 1, 2, 3], [1234, 5, 6, 7], [ 8, 9, 10, 11]]) &gt;&gt;&gt; c array([[ 0, 1, 2, 3, 1234, 5], [ 6, 7, 8, 9, 10, 11]]) 一个数组的切片返回的就是它的视图 &gt;&gt;&gt; a array([[ 0, 1, 2, 3], [1234, 5, 6, 7], [ 8, 9, 10, 11]]) &gt;&gt;&gt; s = a [:, 1:3] &gt;&gt;&gt; s array([[ 1, 2], [ 5, 6], [ 9, 10]]) &gt;&gt;&gt; s[:] = 10 # s[:]是s的视图 &gt;&gt;&gt; s array([[10, 10], [10, 10], [10, 10]]) 深度复制(Deep Copy)copy方法可以完全复制数组和它的数据 &gt;&gt;&gt; a = np.arange(12).reshape((3,4)) &gt;&gt;&gt; a array([[ 0, 1, 2, 3], [ 4, 5, 6, 7], [ 8, 9, 10, 11]]) &gt;&gt;&gt; d = a.copy() &gt;&gt;&gt; d is a False &gt;&gt;&gt; d.base is a False &gt;&gt;&gt; d[0, 0] = 9999 &gt;&gt;&gt; d array([[9999, 1, 2, 3], [ 4, 5, 6, 7], [ 8, 9, 10, 11]]) &gt;&gt;&gt; a array([[ 0, 1, 2, 3], [ 4, 5, 6, 7], [ 8, 9, 10, 11]]) 函数和方法概览如下是按照分类整理的常用函数和方法，完整的分类可以参考Routines 数组创建 arange array copy empty empty_like eye # 创建一个对角线全是1的二维数组 fromfile fromfunction identity # 创建一个对角线全是1的方形矩阵，与eye方法差不多，只是可以接受的参数不同 linspace logspace # 创建等比数列 mgrid orgid ones ones_like zeros zeros_like 转换 ndarray.astype # 改变数组的元素格式 atleast_1d # 将输入转换为至少1维数组 atleast_2d alteast_3d mat # 将输入转换为矩阵 处理 array_split column_stack concatenate diagonal dsplit dstack hsplit hstack ndarray.item newaxis ravel repeat reshape resize squeeze swapaxes take transpose vsplit vstack Questions all any nonezero where 排序 argmax # 返回最大值的索引 argmin # 返回最小值的索引 argsort # 返回排序后的索引 max min ptp searchsorted sort 运算 choose compress cumprod cumsum inner ndarray.fill imag prod put putmask real sum 基本统计 cov mean std var 线性代数 cross dot outer linalg svd vdot Less Basic广播机制属于广播主要描述于numpy对于不同shape的数组如何进行算术运算。受限于一些特定约束。一般都是小的数组扩展为大的数组，以便能计算。 通常情况下，numpy操作的数组必须是相同shape的。 &gt;&gt;&gt; import numpy as np &gt;&gt;&gt; a = np.array([1.0, 2.0, 3.0]) &gt;&gt;&gt; b = np.array([2.0, 2.0, 2.0]) &gt;&gt;&gt; a * b array([ 2., 4., 6.]) 当数组的shape满足某些特定约束时，numpy的广播机制可以使这个约束更宽松。最简单的就是广播例子就是当数组和一个标量操作时。 &gt;&gt;&gt; a = np.array([1.0, 2.0, 3.0]) &gt;&gt;&gt; b = 2.0 &gt;&gt;&gt; a * b array([ 2., 4., 6.]) 上面两个例子的结果是一样的，我们可以认为标量b被扩展为了和a同样shape的数组，b中的新元素就是原来标量的拷贝。这个扩展策略仅仅是概念上的，实际上Numpy足够聪明，能自动使用标量做运算，而不需要复制任何东西。所以广播运算从计算内存上来说更优秀。 要能满足广播，必须符合下面两条规则： 广播之后，输出数组的shape是输入数组shape的各个轴上的最大值，然后沿着较大shape属性的方向复制延伸； 要进行广播机制，要么两个数组的shape属性一样，要么其中有一个数组的shape属性必须有一个等于1； 更多可以参考: https://docs.scipy.org/doc/numpy-dev/user/basics.broadcasting.html http://www.labri.fr/perso/nrougier/from-python-to-numpy/?utm_source=mybridge&amp;utm_medium=blog&amp;utm_campaign=read_more#broadcasting 索引numpy除了支持普通的python方式的索引和切片之外，还支持整数数组或布尔数组索引 数组索引&gt;&gt;&gt; a = np.arange(12) ** 2 &gt;&gt;&gt; i = np.array([1,1,3,8,5]) &gt;&gt;&gt; a array([ 0, 1, 4, 9, 16, 25, 36, 49, 64, 81, 100, 121]) &gt;&gt;&gt; i array([1, 1, 3, 8, 5]) # 返回a中再索引i的元素 &gt;&gt;&gt; a[i] array([ 1, 1, 9, 64, 25]) &gt;&gt;&gt; j = np.array([[3,4], [9,7]]) # 二维数组索引，返回a中在索引j的元素 &gt;&gt;&gt; a[j] array([[ 9, 16], [81, 49]]) 当数组索引作用在多维数组时，是根据数组的第一个维度来索引的。 &gt;&gt;&gt; palette = np.array([ [0 ,0, 0], ... [255, 0, 0], ... [0, 255, 0], ... [0, 0, 255], ... [255, 255, 255] ]) ... &gt;&gt;&gt; image = np.array([ [0, 1, 2, 0], ... [0, 3, 4, 0] ]) ... &gt;&gt;&gt; palette[image] array([[[ 0, 0, 0], [255, 0, 0], [ 0, 255, 0], [ 0, 0, 0]], [[ 0, 0, 0], [ 0, 0, 255], [255, 255, 255], [ 0, 0, 0]]]) 索引同样可以是多维的，但是必须是相同的shape &gt;&gt;&gt; a = np.arange(12).reshape(3, 4) &gt;&gt;&gt; a array([[ 0, 1, 2, 3], [ 4, 5, 6, 7], [ 8, 9, 10, 11]]) # indices for the first dim of a &gt;&gt;&gt; i = np.array([[0,1], ... [1,2] ]) ... # indices for the second dim &gt;&gt;&gt; j = np.array([[2, 1], ... [3, 3] ]) ... # i and j must have equal shape # 返回的结果是是[ [a[0,2], a[1,1] # [a[1,3], a[2, 3] ] &gt;&gt;&gt; a[i, j] array([[ 2, 5], [ 7, 11]]) # [ a[0,2], a[1, 2], # a[1,2], a[2, 2] ] &gt;&gt;&gt; a[i, 2] array([[ 2, 6], [ 6, 10]]) # [[[ a[0,2], a[0,1], # a[0,3], a[0,3]], # # a[1,2], a[1,1], # a[1,3], a[1,3]], # # a[2,2], a[2,1], # a[2,3], a[2,3]]] &gt;&gt;&gt; a[:, j] array([[[ 2, 1], [ 3, 3]], [[ 6, 5], [ 7, 7]], [[10, 9], [11, 11]]]) 同样，我们可以把i和j放在一个列表里，然后用列表做索引 &gt;&gt;&gt; l = [i, j] # 等价于a[i, j] &gt;&gt;&gt; a[l] array([[ 2, 5], [ 7, 11]]) 但是，我们不可以把i和j放在一个数组里，因为数组索引是作用在第一个维度上的。 &gt;&gt;&gt; s = np.array([i, j]) &gt;&gt;&gt; s array([[[0, 1], [1, 2]], [[2, 1], [3, 3]]]) &gt;&gt;&gt; a[s] --------------------------------------------------------------------------- IndexError Traceback (most recent call last) &lt;ipython-input-42-c057dc68e5fe&gt; in &lt;module&gt;() ----&gt; 1 a[s] IndexError: index 3 is out of bounds for axis 0 with size 3 # 等价于 a[i, j] &gt;&gt;&gt; a[tuple(s)] array([[ 2, 5], [ 7, 11]]) 我们同样可以给数组索引赋值 &gt;&gt;&gt; a = np.arange(5) &gt;&gt;&gt; a array([0, 1, 2, 3, 4]) &gt;&gt;&gt; a[[1,3,4]] = 0 &gt;&gt;&gt; a array([0, 0, 2, 0, 0]) 但是当列表包含相同的索引时，这个位置会被赋值多次，最终只保留最后一次的值 &gt;&gt;&gt; a = np.arange(5) &gt;&gt;&gt; a[[0, 0, 2]] = [1,2,3] &gt;&gt;&gt; a array([2, 1, 3, 3, 4]) 上面看起来很合理，但是当使用+=符号的时候，结果和我们想的可能不太一样 &gt;&gt;&gt; a = np.arange(5) &gt;&gt;&gt; a[[0, 0, 2]] += 1 &gt;&gt;&gt; a array([1, 1, 3, 3, 4]) 尽管索引中出现了两次0，但是第0个元素它只加了1次。 布尔数组索引当使用数字数组索引时，我们提供了哪些元素要被索引的信息。但是当使用布尔数组时，我们是明确哪些元素需要，哪些元素不需要。 &gt;&gt;&gt; a = np.arange(12).reshape((3,4)) &gt;&gt;&gt; a array([[ 0, 1, 2, 3], [ 4, 5, 6, 7], [ 8, 9, 10, 11]]) &gt;&gt;&gt; b = a &gt; 4 &gt;&gt;&gt; b array([[False, False, False, False], [False, True, True, True], [ True, True, True, True]], dtype=bool) &gt;&gt;&gt; a[b] array([ 5, 6, 7, 8, 9, 10, 11]) 这个特性非常适合用来赋值 # 所有大于4的元素都赋值为0 &gt;&gt;&gt; a[b] = 0 &gt;&gt;&gt; a array([[0, 1, 2, 3], [4, 0, 0, 0], [0, 0, 0, 0]]) 一个使用布尔数组索引的例子就是曼德博集合(Mandelbrot set) import numpy as np import matplotlib.pyplot as plt def mandelbrot( h,w, maxit=20 ): &quot;&quot;&quot;Returns an image of the Mandelbrot fractal of size (h,w).&quot;&quot;&quot; y,x = np.ogrid[ -1.4:1.4:h*1j, -2:0.8:w*1j ] c = x+y*1j z = c divtime = maxit + np.zeros(z.shape, dtype=int) for i in range(maxit): z = z**2 + c diverge = z*np.conj(z) &gt; 2**2 # who is diverging div_now = diverge &amp; (divtime==maxit) # who is diverging now divtime[div_now] = i # note when z[diverge] = 2 # avoid diverging too much return divtime plt.imshow(mandelbrot(400,400)) plt.show() 另一个布尔数组的场景跟数字数组索引类似，对每个维度，我们提供一个1维的数组来选择我们需要的切片 &gt;&gt;&gt; a = np.arange(12).reshape(3, 4) &gt;&gt;&gt; b1 = np.array([False, True, True]) &gt;&gt;&gt; b2 = np.array([True, False, True, False]) &gt;&gt;&gt; a array([[ 0, 1, 2, 3], [ 4, 5, 6, 7], [ 8, 9, 10, 11]]) # 选择行 &gt;&gt;&gt; a[b1, :] array([[ 4, 5, 6, 7], [ 8, 9, 10, 11]]) # 同上 &gt;&gt;&gt; a[b1] array([[ 4, 5, 6, 7], [ 8, 9, 10, 11]]) # 选择列 &gt;&gt;&gt; a[:, b2] array([[ 0, 2], [ 4, 6], [ 8, 10]]) # a weird thing to do &gt;&gt;&gt; a[b1, b2] array([ 4, 10]) ix_()函数 （作用待定）字符串索引Numpy提供了创建结构化的数组的能力，可以通过列名来操作数据 # dtype分别制定每一个的名字和数据类型 &gt;&gt;&gt; x = np.array([(1, 2., &apos;Hello&apos;), (2, 3., &quot;World&quot;)], dtype=[(&apos;foo&apos;, &apos;i4&apos;), (&apos;bar&apos;, &apos;f4&apos;), (&apos;baz&apos;, &apos;S10&apos;)]) &gt;&gt;&gt; x[1] (2, 3., b&apos;World&apos;) &gt;&gt;&gt; x[&apos;foo&apos;] array([1, 2], dtype=int32) &gt;&gt;&gt; x[&apos;bar&apos;] array([ 2., 3.], dtype=float32) &gt;&gt;&gt; x[&apos;baz&apos;] array([b&apos;Hello&apos;, b&apos;World&apos;], dtype=&apos;|S10&apos;) 更多 Data types Array creation I/O with NumPy Indexing Broadcasting Byte-swapping Structured arrays Subclassing ndarray 扩展阅读 100 numpy exercises 试验性的Numpy教程 From Python to Numpy]]></content>
      <categories>
        <category>python数据分析</category>
      </categories>
      <tags>
        <tag>numpy</tag>
      </tags>
  </entry>
</search>
